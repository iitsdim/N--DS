{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f90460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:22.164202Z",
     "start_time": "2023-07-18T12:24:22.160623Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download ru_core_news_sm\n",
    "\n",
    "# !pip install nltk\n",
    "\n",
    "# !pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fafd1",
   "metadata": {},
   "source": [
    "# Базовые библиотеки для обработки естественного языка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba804a6a",
   "metadata": {},
   "source": [
    "- NLTK\n",
    "- SpaCy\n",
    "- Gensim\n",
    "- TextBlob\n",
    "- Transformers\n",
    "- Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da098f91",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25673c6",
   "metadata": {},
   "source": [
    "## SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54586021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T08:17:51.468518Z",
     "start_time": "2023-07-18T08:17:51.465037Z"
    }
   },
   "source": [
    "- https://spacy.io/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db3677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:32.734718Z",
     "start_time": "2023-07-18T12:24:22.167078Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenize_text(text, language='en_core_web_sm'):\n",
    "    nlp = spacy.load(language)\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample sentence.\"\n",
    "tokens = tokenize_text(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a00e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:34.293075Z",
     "start_time": "2023-07-18T12:24:32.738187Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Привет, как дела?\"\n",
    "tokens = tokenize_text(text, 'ru_core_news_sm')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2a1f7",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae8f06",
   "metadata": {},
   "source": [
    "- https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf299b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:35.977477Z",
     "start_time": "2023-07-18T12:24:34.296653Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text(text, language='english'):\n",
    "    tokens = word_tokenize(text, language)\n",
    "    return tokens\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample sentence.\"\n",
    "tokens = tokenize_text(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e72ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:35.991377Z",
     "start_time": "2023-07-18T12:24:35.980112Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Привет, как дела?\"\n",
    "tokens = tokenize_text(text, 'russian')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859df287",
   "metadata": {},
   "source": [
    "# Lemmatization and stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b285b",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532d366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:36.406829Z",
     "start_time": "2023-07-18T12:24:35.993681Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(text, language='en_core_web_sm'):\n",
    "    nlp = spacy.load(language)\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return lemmas\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample sentence.\"\n",
    "lemmas = lemmatize_text(text)\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f38e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:37.536443Z",
     "start_time": "2023-07-18T12:24:36.410627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Пример использования\n",
    "text = \"Привет, как дела?\"\n",
    "lemmas = lemmatize_text(text, 'ru_core_news_sm')\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec849973",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654fc0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:37.543383Z",
     "start_time": "2023-07-18T12:24:37.539578Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def stem_text(text, language='english'):\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample sentence.\"\n",
    "lemmas = stem_text(text)\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8250a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:37.550235Z",
     "start_time": "2023-07-18T12:24:37.546791Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Привет, как дела?\"\n",
    "stemmed_tokens = stem_text(text, 'russian')\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322c8c2",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962437c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:37.562202Z",
     "start_time": "2023-07-18T12:24:37.552387Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text, language='english'):\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample sentence.\"\n",
    "filtered_text = remove_stopwords(text)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8b454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:37.568954Z",
     "start_time": "2023-07-18T12:24:37.564319Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Привет, как дела?\"\n",
    "filtered_text = remove_stopwords(text, 'russian')\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0af80d",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f29bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:37.971697Z",
     "start_time": "2023-07-18T12:24:37.571360Z"
    }
   },
   "outputs": [],
   "source": [
    "def pos_tagging(text, language='en_core_web_sm'):\n",
    "    nlp = spacy.load(language)\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    return pos_tags\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample sentence.\"\n",
    "pos_tags = pos_tagging(text)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46010159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:39.085793Z",
     "start_time": "2023-07-18T12:24:37.973819Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Привет, как дела?\"\n",
    "pos_tags = pos_tagging(text, 'ru_core_news_sm')\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d755a6",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6205aa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:39.160052Z",
     "start_time": "2023-07-18T12:24:39.088100Z"
    }
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return sentiment\n",
    "\n",
    "# Пример использования\n",
    "text = \"I love this product!\"\n",
    "sentiment = sentiment_analysis(text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7384362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:39.165270Z",
     "start_time": "2023-07-18T12:24:39.162326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Пример использования\n",
    "text = \"Этот фильм просто потрясающий!\"\n",
    "sentiment = sentiment_analysis(text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a90dd",
   "metadata": {},
   "source": [
    "# NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62137ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:39.849606Z",
     "start_time": "2023-07-18T12:24:39.167287Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_named_entities(text, language='en_core_web_sm'):\n",
    "    nlp = spacy.load(language)\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Пример использования\n",
    "text = \"Apple Inc. was founded by Steve Jobs.\"\n",
    "named_entities = extract_named_entities(text)\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c25a1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:40.968113Z",
     "start_time": "2023-07-18T12:24:39.851578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Пример использования\n",
    "text = \"Apple Inc. была основана Стивом Джобсом.\"\n",
    "named_entities = extract_named_entities(text, 'ru_core_news_sm')\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e952d",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8ee3f",
   "metadata": {},
   "source": [
    "## GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20957860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:40.972176Z",
     "start_time": "2023-07-18T12:24:40.970392Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-text\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695cd641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:09.244045Z",
     "start_time": "2023-07-18T12:24:40.980110Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "\n",
    "def text_generation(seed_text, model, tokenizer):\n",
    "    input_text = tokenizer.encode(seed_text, return_tensors='tf')\n",
    "    output = model.generate(input_text, max_length=100, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Пример использования\n",
    "seed_text = \"Once upon a time\"\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = TFGPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "generated_text = text_generation(seed_text, model, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a678e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:23.689972Z",
     "start_time": "2023-07-18T12:25:09.248116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Пример использования\n",
    "seed_text = \"В некотором царстве, в некотором государстве жил-был\"\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = TFGPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "generated_text = text_generation(seed_text, model, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5803e95",
   "metadata": {},
   "source": [
    "## RU GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909822d",
   "metadata": {},
   "source": [
    "- https://huggingface.co/ai-forever/rugpt2large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90553f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:53.601212Z",
     "start_time": "2023-07-18T12:25:23.692690Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_text(prompt):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt2large')\n",
    "    model = GPT2LMHeadModel.from_pretrained('sberbank-ai/rugpt2large')\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Пример использования\n",
    "prompt = \"В некотором царстве, в некотором государстве жил-был\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845977de",
   "metadata": {},
   "source": [
    "# Key word extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc2f072",
   "metadata": {},
   "source": [
    "## YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7ce71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:53.612119Z",
     "start_time": "2023-07-18T12:25:53.605871Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install yake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6baebae",
   "metadata": {},
   "source": [
    "- https://github.com/LIAAD/yake\n",
    "- http://yake.inesctec.pt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816bac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:53.917079Z",
     "start_time": "2023-07-18T12:25:53.615460Z"
    }
   },
   "outputs": [],
   "source": [
    "from yake import KeywordExtractor\n",
    "\n",
    "def extract_keywords(text):\n",
    "    extractor = KeywordExtractor(lan=\"en\") #, n=2\n",
    "    keywords = extractor.extract_keywords(text)\n",
    "    extracted_keywords = [keyword[0] for keyword in keywords]\n",
    "    return extracted_keywords\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample text. We want to extract keywords from it.\"\n",
    "keywords = extract_keywords(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400bbef7",
   "metadata": {},
   "source": [
    "## RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e880814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:53.921734Z",
     "start_time": "2023-07-18T12:25:53.919292Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install rake_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302ab11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T09:22:47.722053Z",
     "start_time": "2023-07-18T09:22:47.718437Z"
    }
   },
   "source": [
    "- https://csurfer.github.io/rake-nltk/_build/html/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447814a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:53.935266Z",
     "start_time": "2023-07-18T12:25:53.923783Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "def extract_keywords_rake(text):\n",
    "    rake = Rake()\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    keywords = rake.get_ranked_phrases()\n",
    "    return keywords\n",
    "\n",
    "# Пример использования\n",
    "text = \"This is a sample text. We want to extract keywords from it.\"\n",
    "keywords = extract_keywords_rake(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4e2d4",
   "metadata": {},
   "source": [
    "# Machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53765147",
   "metadata": {},
   "source": [
    "## translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d91f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:53.938875Z",
     "start_time": "2023-07-18T12:25:53.937263Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b98f50",
   "metadata": {},
   "source": [
    "- https://translate-python.readthedocs.io/en/latest/providers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3558bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:54.906350Z",
     "start_time": "2023-07-18T12:25:53.940858Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "\n",
    "def translate_text(text, source_lang, target_lang):\n",
    "    translator = Translator(from_lang=source_lang, to_lang=target_lang)\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "# Пример использования\n",
    "text = \"Hello, how are you?\"\n",
    "translated_text = translate_text(text, 'en', 'fr')  # Перевод с английского на французский\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fe09d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:55.687603Z",
     "start_time": "2023-07-18T12:25:54.909364Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Bonjour, comment allez-vous ?\"\n",
    "translated_text = translate_text(text, 'fr', 'en')  # Перевод с французского на английский\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f024049",
   "metadata": {},
   "source": [
    "## googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d890e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:55.693178Z",
     "start_time": "2023-07-18T12:25:55.690623Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33530cf4",
   "metadata": {},
   "source": [
    "- https://py-googletrans.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75eeaab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:56.186411Z",
     "start_time": "2023-07-18T12:25:55.696185Z"
    }
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_text(text, source_lang, target_lang):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src=source_lang, dest=target_lang)\n",
    "    translated_text = translation.text\n",
    "    return translated_text\n",
    "\n",
    "# Пример использования\n",
    "text = \"Hello, how are you?\"\n",
    "translated_text = translate_text(text, 'en', 'fr')  # Перевод с английского на французский\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd5024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:56.544841Z",
     "start_time": "2023-07-18T12:25:56.188976Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Bonjour comment allez-vous?\"\n",
    "translated_text = translate_text(text, 'fr', 'en')  # Перевод с французского на английский\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccf0ea",
   "metadata": {},
   "source": [
    "# Text data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52444cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:37:04.814596Z",
     "start_time": "2023-07-18T07:37:04.810592Z"
    }
   },
   "source": [
    "<img src='https://lh6.googleusercontent.com/x3ZAhTDLT1QVSD8gCdaBVMquM2dcYA15A-orfzXyTzhTP8m0ZKLXz_2NrJdWlTgWKRS7BimExM8RO9Ce_uVVVdRR29vGeP0VZdncDZY0GTwkctocQyYg7HK9VL5ay3QC4JhbSXBK'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166c98c",
   "metadata": {},
   "source": [
    "<img src='https://amitness.com/images/nlp-aug-bert-augmentations.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0074a0",
   "metadata": {},
   "source": [
    "<img src='https://editor.analyticsvidhya.com/uploads/67352blog2_da_tech.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9b54c",
   "metadata": {},
   "source": [
    "- Toxic Comment Classification Challenge https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge\n",
    "- Дархан Нурахметов - Мое серебро на toxic-comment-classification-challenge https://www.youtube.com/watch?v=ojbfxPsjDA8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f24b60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:12:58.208885Z",
     "start_time": "2023-07-18T10:12:58.204759Z"
    }
   },
   "source": [
    "Популярные методы аугментации:\n",
    "- Замена синонимов\n",
    "- Удаление слов\n",
    "- Добавление шума\n",
    "- Случайная перестановка слов\n",
    "- Генерация случайных предложений\n",
    "- Замена символов (O->0, 5->%, e->3)\n",
    "- и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6042d",
   "metadata": {},
   "source": [
    "Библиотеки для аугментации текстовых данных:\n",
    "- nlpaug https://github.com/makcedward/nlpaug\n",
    "- TextAttack\n",
    "    - https://github.com/QData/TextAttack\n",
    "    - https://textattack.readthedocs.io/en/latest/2notebook/3_Augmentations.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824c03",
   "metadata": {},
   "source": [
    "## nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5bbd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:56.549989Z",
     "start_time": "2023-07-18T12:25:56.547501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install nlpaug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc880c7",
   "metadata": {},
   "source": [
    "- https://nlpaug.readthedocs.io/en/latest/augmenter/augmenter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f5064",
   "metadata": {},
   "source": [
    "### SynonymAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f7be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:59.532299Z",
     "start_time": "2023-07-18T12:25:56.552684Z"
    }
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "text = \"This is a sample text.\"\n",
    "aug = naw.SynonymAug()\n",
    "\n",
    "# Пример использования\n",
    "augmented_text = aug.augment(text)\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd315e7",
   "metadata": {},
   "source": [
    "### RandomWordAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f405fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:59.538173Z",
     "start_time": "2023-07-18T12:25:59.534614Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"This is a sample text.\"\n",
    "aug = naw.RandomWordAug(action=\"swap\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98473e29",
   "metadata": {},
   "source": [
    "### ContextualWordEmbsAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739337b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:26:01.725840Z",
     "start_time": "2023-07-18T12:25:59.541945Z"
    }
   },
   "outputs": [],
   "source": [
    "text = 'the brown fox jumps over the lazy dog'\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc40e8",
   "metadata": {},
   "source": [
    "### BackTranslationAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d75c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:26:01.731110Z",
     "start_time": "2023-07-18T12:26:01.728878Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8555af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:26:14.917683Z",
     "start_time": "2023-07-18T12:26:01.733957Z"
    }
   },
   "outputs": [],
   "source": [
    "aug = naw.BackTranslationAug()\n",
    "text = 'the brown fox jumps over the lazy dog'\n",
    "augmented_text = aug.augment(text)\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67883fad",
   "metadata": {},
   "source": [
    "### KeyboardAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86423a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:26:14.935033Z",
     "start_time": "2023-07-18T12:26:14.920632Z"
    }
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "text = \"This is a sample text.\"\n",
    "aug = nac.KeyboardAug()\n",
    "augmented_text = aug.augment(text)\n",
    "\n",
    "# Пример использования\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34923866",
   "metadata": {},
   "source": [
    "Статьи про аугментацию для текстовых данных:\n",
    "- https://neptune.ai/blog/data-augmentation-nlp\n",
    "- https://www.freecodecamp.org/news/how-to-perform-data-augmentation-in-nlp-projects/\n",
    "- https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff\n",
    "- https://www.analyticsvidhya.com/blog/2022/02/text-data-augmentation-in-natural-language-processing-with-texattack/\n",
    "- https://amitness.com/2020/05/data-augmentation-for-nlp/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "318.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
